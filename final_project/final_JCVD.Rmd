---
title: "Final Project[^*]"
subtitle: "PSTAT 231"
author: "Villaseñor-Derbez J.C. | 8749749"
output: 
  bookdown::pdf_document2: 
    fig_caption: yes
---

[^*]: Code available on GitHUb at: https://github.com/jcvdav/PSTAT231/tree/master/final_project

1. What makes voter behavior prediction (and thus election forecasting) a hard problem?

2. What was unique to Nate Silver’s approach in 2012 that allowed him to achieve good predictions?

3. What went wrong in 2016? What do you think should be done to make future predictions better?

```{r echo = F}
suppressPackageStartupMessages({
  library(startR)
  library(here)
  library(maps)
  library(sf)
  library(dendextend)
  library(tidyverse)
})
```

```{r, echo = F}
# Some housekeeping
update_geom_defaults("point", list(fill = "steelblue",
                                   color = "black",
                                   shape = 21,
                                   size = 2))

update_geom_defaults("bar", list(fill = "steelblue",
                                 color = "black",
                                 size = 1))

update_geom_defaults("col", list(fill = "steelblue",
                                 color = "black",
                                 size = 1))

update_geom_defaults("boxplot", list(fill = "steelblue",
                                     color = "black",
                                     size = 1))

update_geom_defaults("line", list(color = "black",
                                  size = 1))

update_geom_defaults("density", list(fill = "steelblue",
                                     color = "black",
                                     size = 1,
                                     alpha = 0.5))
# 
# update_geom_defaults("density_ridges", list(fill = "steelblue",
#                                      color = "black",
#                                      size = 1,
#                                      alpha = 0.5))

update_geom_defaults("ribbon", list(fill = "steelblue",
                                     color = "transparent",
                                     size = 0,
                                     alpha = 0.5))

update_geom_defaults("rug", list(color = "black",
                                 size = 1))

update_geom_defaults("sf", list(color = "black"))

# Set global theme
theme_set(startR::ggtheme_plot())
```


4. Remove summary rows from election.raw data:

- Federal-level summary into a election_federal.

- State-level summary into a election_state.

- Only county-level data is to be in election.

```{r}
election_raw <- read.csv(here("data", "election", "election.csv")) %>%
  as_tibble()

census_meta <- read.csv(here("data", "census", "metadata.csv"), sep = ";") %>%
  as_tibble()

census <- read.csv(here("data", "census","census.csv")) %>%
  as_tibble() %>% 
  mutate(CensusTract = as.factor(CensusTract))
```

```{r}
election_federal <- election_raw %>% 
  filter(fips == "US")

election_state <- election_raw %>% 
  filter(state != "US", is.na(county))

election <- election_raw %>% 
  filter(!is.na(county))
```

5. How many named presidential candidates were there in the 2016 election? Draw a bar chart of all votes received by each candidate

There were `r length(unique(election_federal$candidate)) - 1` explicitly mentioned presidential candidates, plus a category of `None of these acandidates`. Figure \@ref(fig:candidate-votes) shows the votes (on a $log_{10}$-scale) that each candidate received.

```{r candidate-votes, fig.height = 6, fig.width = 5, fig.cap = "Number of votes that each presidential candidate received in the 2018 Presidential Elections."}
election_federal %>% 
  group_by(candidate) %>% 
  summarize(votes = sum(votes, na.rm = T)) %>% 
  ungroup() %>% 
  mutate(candidate = fct_reorder(.f = candidate, .x = votes)) %>% 
  ggplot(aes(x = candidate, y = votes)) +
  geom_col() +
  coord_flip() +
  scale_y_continuous(trans = "log10") +
  labs(x = "Candidate", y = "Votes (log-10 Scale)")
```


6. Create variables `county_winner` and `state_winner` by taking the candidate with the highest proportion of votes. Hint: to create `county_winner`, start with election, group by `fips`, compute total votes, and `pct = votes/total`. Then choose the highest row using `top_n` (variable `state_winner` is similar).

```{r}
county_winner <- election %>% 
  group_by(fips) %>% 
  mutate(total = sum(votes),
         pct = votes / total) %>% 
  top_n(1) %>% 
  ungroup() %>% 
  select(fips, winner = candidate) %>% 
  mutate(fips = as.numeric(as.character(fips)))

state_winner <- election_state %>% 
  group_by(state) %>% 
  mutate(total = sum(votes),
         pct = votes / total) %>% 
  top_n(1) %>% 
  ungroup() %>% 
  select(state, winner = candidate) %>% 
  mutate(state = as.character(state))
```

7. Draw county-level map by creating `counties = map_data("county")`. Color by county

```{r}
my_fun <- function(long, lat) {
  # long <- data$long
  # lat <- data$lat
  
  data <- cbind(long, lat) %>% 
    rbind(cbind(long[1], lat[1]))
  st_sfc(st_polygon(list(as.matrix(data))))
}

state_dictionary <- tibble(abb = state.abb, state = tolower(state.name))

states <- map_data("state") %>% 
  group_by(group, region) %>% 
  summarize(geometry = my_fun(long, lat)) %>% 
  ungroup() %>% 
  st_sf(crs = 4326) %>% 
  left_join(state_dictionary, by = c("region" = "state"))

counties <- map_data("county") %>% 
  group_by(group, region, subregion) %>% 
  summarize(geometry = my_fun(long, lat)) %>% 
  ungroup() %>% 
  st_sf(crs = 4326)
```

```{r}
ggplot(data = counties,
       mapping = aes(fill = subregion)) +
  geom_sf(data = counties, color = "white") +
  ggtheme_map() +
  theme(legend.position = "None")
```

Now color the map by the winning candidate for each state. First, combine states variable and `state_winner` we created earlier using `left_join()`. Note that `left_join()` needs to match up values of states to join the tables; however, they are in different formats: e.g. AZ vs. arizona. Before using `left_join()`, create a common column by creating a new column for states named `fips = state.abb[match(some_column, some_function(state.name))]`. Replace `some_column` and `some_function` to complete creation of this new column. Then `left_join()`. Your figure will look similar to `state_level` New York Times map.

```{r}
states %>% 
  left_join(state_winner, by = c("abb" = "state")) %>% 
  ggplot(mapping = aes(fill = winner)) +
  geom_sf(color = "white") +
  ggtheme_map() +
  scale_fill_brewer(palette = "Set1") +
  guides(fill = guide_legend(title = "Winner"))
```

9. The variable `county` does not have `fips` column. So we will create one by pooling information from `maps::county.fips`. Split the `polyname` column to `region` and `subregion`. Use `left_join()` to combine `county.fips` into county. Also, `left_join()` previously created variable `county_winner`. Your figure will look similar to county-level New York Times map.



```{r}
county_fips <- maps::county.fips %>% 
  mutate(region = str_extract(polyname, ".+,"),
         subregion = str_extract(polyname, ",.+"),
         region = str_remove(region, ","),
         subregion = str_remove(subregion, ",")) %>% 
  select(-polyname)

counties %>% 
  left_join(county_fips, by = c("region", "subregion")) %>% 
  left_join(county_winner, by = "fips") %>% 
  ggplot(mapping = aes(fill = winner)) +
  geom_sf(color = "white") +
  ggtheme_map() +
  scale_fill_brewer(palette = "Set1") +
  guides(fill = guide_legend(title = "Winner"))
```

10. Create a visualization of your choice using census data. Many exit polls noted that demographics played a big role in the election. Use this Washington Post article and this R graph gallery for ideas and inspiration.

I am going to use the census data and electoral outcomes to build a logistic regression model. In this case, I will use only demographics and population size as predictors for winning candidate at the county level. I begin by creating a dataset where I calculate the average measure across all demographics at the county level.

```{r}
model_data <- census %>% 
  select(-CensusTract) %>% 
  group_by(State, County) %>% 
  summarise_all(mean, na.rm = T) %>% 
  ungroup() %>% 
  mutate(State = tolower(State),
         County = tolower(County)) %>% 
  rename(region = State,
         subregion = County) %>% 
  left_join(county_fips, by = c("region", "subregion")) %>% 
  left_join(county_winner, by = "fips") %>% 
  drop_na(winner) %>% 
  mutate(winner = ifelse(winner == "Hillary Clinton", 0, 1)) %>%
  select(-fips)
```

I then fit a binary logistic regression, which predicts Hillary / Trump as options.

```{r}
model <- glm(winner ~  TotalPop + Men + Hispanic + White + Black + Native + Asian + Pacific + Citizen, data = model_data, family = binomial)
```

I then take the predictions and plot them on a map. The map showing the predicted outcomes suggests that demographics are good predictors of election results. A regression table is also included.

```{r}
model_pred <- model_data %>% 
  mutate(prediction = model$fitted.values,
         prediction = ifelse(prediction <= 0.5, "Hillary Clinton", "Donald Trump")) %>% 
  select(region, subregion, prediction, winner)

counties %>% 
  left_join(model_pred, by = c("region", "subregion")) %>% 
  ggplot(mapping = aes(fill = prediction)) +
  geom_sf(color = "white") +
  ggtheme_map() +
  scale_fill_brewer(palette = "Set1") +
  guides(fill = guide_legend(title = "Predicted winner"))
  
```

```{r, results = "asis"}
stargazer::stargazer(model,
                     single.row = T,
                     header = F)
```

11. The census data contains high resolution information (more fine-grained than county-level). In this problem, we aggregate the information into county-level data by computing TotalPop-weighted average of each attributes for each county. Create the following variables:

- Clean census data census.del: start with census, filter out any rows with missing values, convert {Men, Employed, Citizen} attributes to a percentages (meta data seems to be inaccurate), compute Minority attribute by combining {Hispanic, Black, Native, Asian, Pacific}, remove {Walk, PublicWork, Construction}.

Many columns seem to be related, and, if a set that adds up to 100%, one column will be deleted.

```{r}
census_del <- census %>% 
  drop_na() %>% 
  mutate(Men = Men / TotalPop,
         Employed = Employed / TotalPop,
         Citizen = Citizen / TotalPop,
         minority = Hispanic + Black + Native + Asian + Pacific) %>% 
  select(-c(Walk, PublicWork, Construction, Hispanic, Black, Native, Asian, Pacific, Women, White))
```

- Sub-county census data, census.subct : start with census.del from above, group_by() two attributes {State, County}, use add_tally() to compute CountyTotal. Also, compute the weight by TotalPop/CountyTotal.

```{r}
census_subct <- census_del %>% 
  group_by(State, County) %>% 
  mutate(CountyTotal = sum(TotalPop)) %>% 
  mutate(weight = TotalPop / CountyTotal)
```


- County census data, census.ct : start with census.subct, use summarize_at() to compute weighted sum

```{r}
census_ct <- census_subct %>% 
  summarize_at(.vars = vars(Men, Citizen, Income, IncomeErr, IncomePerCap, IncomePerCapErr, Poverty, ChildPoverty, Professional, Service, Office, Production, Drive, Carpool, Transit, OtherTransp, WorkAtHome, MeanCommute, Employed, PrivateWork, SelfEmployed, FamilyWork, Unemployment, minority), funs(weighted.mean(., w = weight)))
```

- Print few rows of census.ct :


```{r}
head(census_ct)
```

12. Run PCA for both county & sub-county level data. Save the first two principle components PC1 and PC2 into a two-column data frame, call it ct.pc and subct.pc, respectively.

```{r}
census_subct_pca <- census_subct %>% 
  ungroup() %>% 
  select(-c(CensusTract, State, County, CountyTotal, weight)) %>% 
  prcomp(scale = T)

census_ct_pca <- census_ct %>% 
  ungroup() %>% 
  select(-c(State, County)) %>% 
  prcomp(scale = T)

subct_pc <- tibble(PC1 = census_subct_pca$x[, 1],
                   PC2 = census_subct_pca$x[, 2])

ct_pc <- tibble(PC1 = census_ct_pca$x[, 1],
                PC2 = census_ct_pca$x[, 2])
```


What are the most prominent loadings?

I calculate the total magnitude between the first two PCs, and then order them in descending order. For the subcounty data, the top 10 loadings are for the variables shown below. These same variables (arrows) can be seen in the biplot below.

```{r}
tibble(var = rownames(census_subct_pca$rotation),
       l1 = census_subct_pca$rotation[, 1],
       l2 = census_subct_pca$rotation[, 2]) %>% 
  mutate(l = sqrt(l1 ^ 2 + l2 ^ 2)) %>% 
  arrange(desc(l)) %>% 
  head(10)
```

```{r}
biplot(census_subct_pca, xlabs = rep(".", nrow(census_subct)))
```


For the county-level data, the top 10 variables are shown in the table, and then again in the biplot.

```{r}
tibble(var = rownames(census_ct_pca$rotation),
       l1 = census_ct_pca$rotation[, 1],
       l2 = census_ct_pca$rotation[, 2]) %>% 
  mutate(l = sqrt(l1 ^ 2 + l2 ^ 2)) %>% 
  arrange(desc(l)) %>% 
  head(10)
```

```{r}
biplot(census_ct_pca, xlabs = rep(".", nrow(census_ct)))
```


13. With census.ct, perform hierarchical clustering using Euclidean distance metric complete linkage to find 10 clusters. Repeat clustering process with the first 5 principal components of ct.pc. Compare and contrast clusters containing San Mateo County. Can you hypothesize why this would be the case?

```{r}
census_ct_clust <- census_ct %>% 
  ungroup() %>% 
  select(-c(State, County)) %>% 
  scale() %>% 
  dist() %>% 
  hclust(method = "complete")
```


```{r, fig.height = 6, fig.width = 6}
census_ct_clust %>% 
  as.dendrogram() %>% 
  color_labels(k = 10) %>% 
  color_branches(k = 10) %>% 
  set_labels(labels = census_ct$County) %>%
  plot(horiz = TRUE)
```

```{r}
census_ct_pca_clust <- census_ct_pca$x[, 1:5] %>% 
  scale() %>% 
  dist() %>% 
  hclust(method = "complete")

census_ct_pca_clust %>% 
  as.dendrogram() %>% 
  color_labels(k = 10) %>% 
  color_branches(k = 10) %>% 
  set_labels(labels = census_ct$County) %>%
  plot(horiz = TRUE)
```






























